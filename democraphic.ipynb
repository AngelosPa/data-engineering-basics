{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MSwbZ8I0FIE"
      },
      "source": [
        "# Chapter one\n",
        "Collect data from the web.\n",
        "To do this, we need a Python library for web scraping to automate the collection of demographic information. I have chosen BeautifulSoup to do the job.\n",
        "\n",
        "Create a dataFrame to store the collected data:\n",
        "I chose the Pandas library for this\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XgXBWfrN7pGd"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRYuoRRsJF0I"
      },
      "source": [
        "wwwww.wikipedia.org is a great place to start with web scraping . be aware of the structure of HTML in order to extract the text that you wish. Â    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9rQ4H-IUI9m5"
      },
      "outputs": [],
      "source": [
        "array_cities= []\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_cities_in_the_European_Union_by_population_within_city_limits\"\n",
        "headers = {'Accept-Language': 'en-US,en;q=0.8'}\n",
        "response = requests.get(url, headers=headers)\n",
        "eu_cities_unstructured = BeautifulSoup(response.content, 'html.parser')\n",
        "eu_cities_unstructured\n",
        "table = eu_cities_unstructured.find('table', {'class':'wikitable sortable'})\n",
        "rows = table.find_all('tr')\n",
        "headers = [th.text.strip() for th in rows[0].find_all('th')]\n",
        "eu_cities =[]\n",
        "population = []\n",
        "country = []\n",
        "latitude = []\n",
        "longitude = []\n",
        "for row in rows[1:]:\n",
        "      eu_cities.append(row.find_all('td')[1].get_text())\n",
        "      population.append(row.find_all('td')[3].get_text())\n",
        "      country.append(row.find_all('td')[2].get_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBLUlwjBKQ50"
      },
      "source": [
        "To get the coordinates for each of the cities we choose we need to use an other link. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rjyTOpuql-09"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [8], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m    headers \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mAccept-Language\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39men-US,en;q=0.8\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[0;32m      7\u001b[0m    response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url, headers\u001b[39m=\u001b[39mheaders)\n\u001b[1;32m----> 8\u001b[0m    eu_cities_coordinates\u001b[39m.\u001b[39mappend(BeautifulSoup(response\u001b[39m.\u001b[39;49mcontent, \u001b[39m'\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      9\u001b[0m \u001b[39m# to get coordinates\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m city \u001b[39min\u001b[39;00m eu_cities_coordinates:\n",
            "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39minitialize_soup(\u001b[39mself\u001b[39m)\n\u001b[0;32m    332\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed()\n\u001b[0;32m    334\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m# Convert the document to Unicode.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mreset()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mfeed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup)\n\u001b[0;32m    452\u001b[0m \u001b[39m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendData()\n",
            "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    397\u001b[0m parser\u001b[39m.\u001b[39msoup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoup\n\u001b[0;32m    398\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     parser\u001b[39m.\u001b[39;49mfeed(markup)\n\u001b[0;32m    400\u001b[0m     parser\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    401\u001b[0m \u001b[39mexcept\u001b[39;00m HTMLParseError \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\html\\parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[39mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39mas you want (may include '\\n').\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m+\u001b[39m data\n\u001b[1;32m--> 110\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoahead(\u001b[39m0\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\html\\parser.py:172\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    170\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_starttag(i)\n\u001b[0;32m    171\u001b[0m \u001b[39melif\u001b[39;00m startswith(\u001b[39m\"\u001b[39m\u001b[39m</\u001b[39m\u001b[39m\"\u001b[39m, i):\n\u001b[1;32m--> 172\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_endtag(i)\n\u001b[0;32m    173\u001b[0m \u001b[39melif\u001b[39;00m startswith(\u001b[39m\"\u001b[39m\u001b[39m<!--\u001b[39m\u001b[39m\"\u001b[39m, i):\n\u001b[0;32m    174\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_comment(i)\n",
            "File \u001b[1;32mc:\\Users\\mrpal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\html\\parser.py:392\u001b[0m, in \u001b[0;36mHTMLParser.parse_endtag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    391\u001b[0m gtpos \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mend()\n\u001b[1;32m--> 392\u001b[0m match \u001b[39m=\u001b[39m endtagfind\u001b[39m.\u001b[39;49mmatch(rawdata, i) \u001b[39m# </ + tag + >\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m match:\n\u001b[0;32m    394\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcdata_elem \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# to append information into different arrays \n",
        "eu_cities_coordinates = []\n",
        "\n",
        "for link in eu_cities:\n",
        "   url = f'https://en.wikipedia.org/wiki/{link}'\n",
        "   headers = {'Accept-Language': 'en-US,en;q=0.8'}\n",
        "   response = requests.get(url, headers=headers)\n",
        "   eu_cities_coordinates.append(BeautifulSoup(response.content, 'html.parser'))\n",
        "# to get coordinates\n",
        "for city in eu_cities_coordinates:\n",
        "     if (len(city.select(\"span .latitude\")) ==0):\n",
        "        latitude.append(0)\n",
        "        longitude.append(0)\n",
        "     else:\n",
        "      latitude.append(city.select(\"span .latitude\")[0].get_text())\n",
        "      longitude.append(city.select(\"span .longitude\")[0].get_text())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcSkcrHQKm5S"
      },
      "source": [
        "\n",
        "\n",
        "Finally we can make the dataframe. Make sure that the arrays have the same length or there aren't any missing values.\n",
        "after web scraping is always necessary to process to some data cleaning \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "s7Y9MpteJRF9",
        "outputId": "040dbcfe-7184-4c3c-ce1e-d00d7b49fb17"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eu_cities</th>\n",
              "      <th>population</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Berlin</td>\n",
              "      <td>3,677,472\\n</td>\n",
              "      <td>Germany\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Madrid</td>\n",
              "      <td>3,305,408\\n</td>\n",
              "      <td>Spain\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rome</td>\n",
              "      <td>2,761,632\\n</td>\n",
              "      <td>Italy\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  eu_cities   population    country\n",
              "0    Berlin  3,677,472\\n  Germany\\n\n",
              "1    Madrid  3,305,408\\n    Spain\\n\n",
              "2      Rome  2,761,632\\n    Italy\\n"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "cities_dictionary = {}\n",
        "values =[eu_cities, population, country\n",
        "     #     , latitude, longitude\n",
        "         ]\n",
        "cols =[\"eu_cities\", \"population\", \"country\"\n",
        "     #   , \"latitude\", \"longitude\"\n",
        "       ]\n",
        "for key, value in zip(cols, values):\n",
        "     cities_dictionary[key] = value\n",
        "# countries\n",
        "cities_df = pd.DataFrame(cities_dictionary).head(30)\n",
        "cities_df.head(3)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e5d44d20471fed6b31c84e96a507e39677b7979bf00486c2e6552218c91082f0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
